{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "import datetime\n",
    "import itertools\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "from collections import defaultdict\n",
    "from itertools import groupby\n",
    "from geopy.distance import distance\n",
    "from collections import Counter\n",
    "\n",
    "from predictability import *\n",
    "\n",
    "pd.options.mode.chained_assignment = None  # default='warn'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"/data/users_data/douglas/data/\"\n",
    "df_name = \"macaco\"\n",
    "df_path = os.path.join(data_dir, df_name + \"_pandas.tsv\") \n",
    "df_type = \"next_cell\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_filter_data(dataset_name):\n",
    "    \"\"\"\n",
    "    Read the data and create a dataframe.\n",
    "    \"\"\"\n",
    "    df = pd.DataFrame(pd.read_csv(dataset_name, encoding='utf-8', sep=\"\\t\"))\n",
    "\n",
    "    # Filter groups according to size.\n",
    "    df = df.groupby('device_id').filter(lambda x: len(x) >= 170 and len(x) < 6000 and len(set(x)) >= 2) \n",
    "    df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    # Remove rows with NAs.\n",
    "    df.dropna(inplace=True)\n",
    "\n",
    "    # Convert column to datetime format.\n",
    "    df['timestamp'] = pd.to_datetime(df['timestamp'], errors=\"raise\")\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "def create_grid(df, grid_side_length):\n",
    "    \"\"\"\n",
    "    Assigns a grid identifier to every location in the dataset.\n",
    "    The cells of the grid are squares whose side has length 'grid_side_length'.\n",
    "    \"\"\"\n",
    "    bottom_left = (min(df['lat']), min(df['lon']))\n",
    "    bottom_right = (min(df['lat']), max(df['lon']))\n",
    "    top_left = (max(df['lat']), min(df['lon']))\n",
    "    top_right = (max(df['lat']), max(df['lon']))\n",
    "\n",
    "    nr_rows = int(distance(bottom_left, top_left).meters // grid_side_length)\n",
    "    nr_cols = int(distance(bottom_left, bottom_right).meters // grid_side_length)\n",
    "\n",
    "    rows = np.linspace(bottom_left[0], top_left[0], num = nr_rows)\n",
    "    cols = np.linspace(bottom_left[1], bottom_right[1], num = nr_cols)\n",
    "    \n",
    "    df['row'] = np.searchsorted(cols, df['lon'])\n",
    "    df['col'] = np.searchsorted(rows, df['lat'])\n",
    "    \n",
    "    df['grid_id' + str(grid_side_length)] = df['row'] * nr_rows + df['col']\n",
    "    df['grid_id' + str(grid_side_length)] = pd.to_numeric(df['grid_id' + str(grid_side_length)], downcast='integer')\n",
    "    df['grid_id' + str(grid_side_length)] = df['grid_id' + str(grid_side_length)].apply(str)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating grid of side length = 300 meters\n",
      "Creating grid of side length = 400 meters\n",
      "Creating grid of side length = 500 meters\n",
      "Creating grid of side length = 600 meters\n",
      "Creating grid of side length = 700 meters\n",
      "Creating grid of side length = 800 meters\n",
      "Creating grid of side length = 900 meters\n",
      "Creating grid of side length = 1000 meters\n"
     ]
    }
   ],
   "source": [
    "# Preprocess the data.\n",
    "df = load_and_filter_data(df_path)\n",
    "\n",
    "# Create grid of default size (200m side length)\n",
    "df = create_grid(df, 200)\n",
    "\n",
    "# Create grids with other sizes. We only do this for the GPS dataset.\n",
    "if df_name == \"macaco\":\n",
    "    for i in range(300, 1100, 100):\n",
    "        print(\"Creating grid of side length = {} meters\".format(i))\n",
    "        df = create_grid(df, i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop unnecessary columns and rename default grid column.\n",
    "df.rename(columns={'grid_id200':'grid_id'}, inplace=True)\n",
    "df.drop(['lat', 'lon', 'row', 'col'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>measurement_id</th>\n",
       "      <th>device_id</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>grid_id</th>\n",
       "      <th>grid_id300</th>\n",
       "      <th>grid_id400</th>\n",
       "      <th>grid_id500</th>\n",
       "      <th>grid_id600</th>\n",
       "      <th>grid_id700</th>\n",
       "      <th>grid_id800</th>\n",
       "      <th>grid_id900</th>\n",
       "      <th>grid_id1000</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>434778</td>\n",
       "      <td>7795f7ff6b0331c9341c26b471f7be41575d9c9ee6f5f5...</td>\n",
       "      <td>2015-03-17 11:06:42+00:00</td>\n",
       "      <td>1843891497</td>\n",
       "      <td>819515606</td>\n",
       "      <td>460961560</td>\n",
       "      <td>295014247</td>\n",
       "      <td>204885107</td>\n",
       "      <td>150527670</td>\n",
       "      <td>115245044</td>\n",
       "      <td>91053383</td>\n",
       "      <td>73752814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>434782</td>\n",
       "      <td>7795f7ff6b0331c9341c26b471f7be41575d9c9ee6f5f5...</td>\n",
       "      <td>2015-03-17 11:10:43+00:00</td>\n",
       "      <td>1843891497</td>\n",
       "      <td>819515606</td>\n",
       "      <td>460961560</td>\n",
       "      <td>295014247</td>\n",
       "      <td>204885107</td>\n",
       "      <td>150527670</td>\n",
       "      <td>115245044</td>\n",
       "      <td>91053383</td>\n",
       "      <td>73752814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>434783</td>\n",
       "      <td>7795f7ff6b0331c9341c26b471f7be41575d9c9ee6f5f5...</td>\n",
       "      <td>2015-03-17 11:11:11+00:00</td>\n",
       "      <td>1843891497</td>\n",
       "      <td>819515606</td>\n",
       "      <td>460961560</td>\n",
       "      <td>295014247</td>\n",
       "      <td>204885107</td>\n",
       "      <td>150527670</td>\n",
       "      <td>115245044</td>\n",
       "      <td>91053383</td>\n",
       "      <td>73752814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>434785</td>\n",
       "      <td>7795f7ff6b0331c9341c26b471f7be41575d9c9ee6f5f5...</td>\n",
       "      <td>2015-03-17 11:13:11+00:00</td>\n",
       "      <td>1843850253</td>\n",
       "      <td>819515606</td>\n",
       "      <td>460961560</td>\n",
       "      <td>295014247</td>\n",
       "      <td>204885107</td>\n",
       "      <td>150527670</td>\n",
       "      <td>115245044</td>\n",
       "      <td>91053383</td>\n",
       "      <td>73752814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>434805</td>\n",
       "      <td>7795f7ff6b0331c9341c26b471f7be41575d9c9ee6f5f5...</td>\n",
       "      <td>2015-03-17 11:19:06+00:00</td>\n",
       "      <td>1843850253</td>\n",
       "      <td>819515606</td>\n",
       "      <td>460961561</td>\n",
       "      <td>295014247</td>\n",
       "      <td>204885107</td>\n",
       "      <td>150527670</td>\n",
       "      <td>115245044</td>\n",
       "      <td>91053383</td>\n",
       "      <td>73752814</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   measurement_id                                          device_id  \\\n",
       "0          434778  7795f7ff6b0331c9341c26b471f7be41575d9c9ee6f5f5...   \n",
       "1          434782  7795f7ff6b0331c9341c26b471f7be41575d9c9ee6f5f5...   \n",
       "2          434783  7795f7ff6b0331c9341c26b471f7be41575d9c9ee6f5f5...   \n",
       "3          434785  7795f7ff6b0331c9341c26b471f7be41575d9c9ee6f5f5...   \n",
       "4          434805  7795f7ff6b0331c9341c26b471f7be41575d9c9ee6f5f5...   \n",
       "\n",
       "                  timestamp     grid_id grid_id300 grid_id400 grid_id500  \\\n",
       "0 2015-03-17 11:06:42+00:00  1843891497  819515606  460961560  295014247   \n",
       "1 2015-03-17 11:10:43+00:00  1843891497  819515606  460961560  295014247   \n",
       "2 2015-03-17 11:11:11+00:00  1843891497  819515606  460961560  295014247   \n",
       "3 2015-03-17 11:13:11+00:00  1843850253  819515606  460961560  295014247   \n",
       "4 2015-03-17 11:19:06+00:00  1843850253  819515606  460961561  295014247   \n",
       "\n",
       "  grid_id600 grid_id700 grid_id800 grid_id900 grid_id1000  \n",
       "0  204885107  150527670  115245044   91053383    73752814  \n",
       "1  204885107  150527670  115245044   91053383    73752814  \n",
       "2  204885107  150527670  115245044   91053383    73752814  \n",
       "3  204885107  150527670  115245044   91053383    73752814  \n",
       "4  204885107  150527670  115245044   91053383    73752814  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter the dataset in case the prediction task is next place prediction.\n",
    "if df_type == \"next_place\":\n",
    "    df = df.loc[(df['grid_id'].shift() != df['grid_id'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 61 users in the dataset.\n",
      "Average sequence size: 2388.8852459016393, and standard deviation: 1794.054060065653\n"
     ]
    }
   ],
   "source": [
    "# Prints basic information about the dataset.\n",
    "print(\"There are {} users in the dataset.\".format(len(set(df['device_id']))))\n",
    "\n",
    "avg_seq_size = np.mean([len(grp['grid_id']) for _, grp in df.groupby('device_id')])\n",
    "stddev_seq_size = np.std([len(grp['grid_id']) for _, grp in df.groupby('device_id')])\n",
    "print(\"Average sequence size: {}, and standard deviation: {}\".format(avg_seq_size, stddev_seq_size))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute Regularity, Stationarity and Diversity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(df, colname):\n",
    "    \"\"\"\n",
    "    Compute some mobility-related metrics: stationarity, regularity, and diversity of trajectories.\n",
    "    \"\"\"\n",
    "    regularities = defaultdict()\n",
    "    stationarities = defaultdict()\n",
    "    diversities = defaultdict()\n",
    "\n",
    "    nr_users = len(set(df['device_id']))\n",
    "    curr_user = 0\n",
    "    for device_id, grp in df.groupby(df['device_id']):\n",
    "        curr_user += 1        \n",
    "        if curr_user % 20 == 0:\n",
    "            print(\"Processing user {}/{}\".format(str(curr_user), str(nr_users)))\n",
    "        \n",
    "        locs = [str(row[colname]) for _, row in grp.iterrows()]\n",
    "\n",
    "        # Compute metrics.\n",
    "        regularities[device_id] = regularity(locs)\n",
    "        stationarities[device_id] = stationarity(locs)\n",
    "        diversities[device_id] = diversity(locs)\n",
    "    return regularities, stationarities, diversities\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute metrics for the default grid length (200 meters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing user 20/61\n",
      "Processing user 40/61\n",
      "Processing user 60/61\n"
     ]
    }
   ],
   "source": [
    "regularities, stationarities, diversities = compute_metrics(df, 'grid_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['regularity'] = df.apply(lambda row: regularities[row['device_id']], axis=1)\n",
    "df['stationarity'] = df.apply(lambda row: stationarities[row['device_id']], axis=1)\n",
    "df['diversity'] = df.apply(lambda row: diversities[row['device_id']], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>measurement_id</th>\n",
       "      <th>device_id</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>grid_id</th>\n",
       "      <th>grid_id300</th>\n",
       "      <th>grid_id400</th>\n",
       "      <th>grid_id500</th>\n",
       "      <th>grid_id600</th>\n",
       "      <th>grid_id700</th>\n",
       "      <th>grid_id800</th>\n",
       "      <th>grid_id900</th>\n",
       "      <th>grid_id1000</th>\n",
       "      <th>regularity</th>\n",
       "      <th>stationarity</th>\n",
       "      <th>diversity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>434778</td>\n",
       "      <td>7795f7ff6b0331c9341c26b471f7be41575d9c9ee6f5f5...</td>\n",
       "      <td>2015-03-17 11:06:42+00:00</td>\n",
       "      <td>1843891497</td>\n",
       "      <td>819515606</td>\n",
       "      <td>460961560</td>\n",
       "      <td>295014247</td>\n",
       "      <td>204885107</td>\n",
       "      <td>150527670</td>\n",
       "      <td>115245044</td>\n",
       "      <td>91053383</td>\n",
       "      <td>73752814</td>\n",
       "      <td>99.75</td>\n",
       "      <td>76.8</td>\n",
       "      <td>0.985691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>434782</td>\n",
       "      <td>7795f7ff6b0331c9341c26b471f7be41575d9c9ee6f5f5...</td>\n",
       "      <td>2015-03-17 11:10:43+00:00</td>\n",
       "      <td>1843891497</td>\n",
       "      <td>819515606</td>\n",
       "      <td>460961560</td>\n",
       "      <td>295014247</td>\n",
       "      <td>204885107</td>\n",
       "      <td>150527670</td>\n",
       "      <td>115245044</td>\n",
       "      <td>91053383</td>\n",
       "      <td>73752814</td>\n",
       "      <td>99.75</td>\n",
       "      <td>76.8</td>\n",
       "      <td>0.985691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>434783</td>\n",
       "      <td>7795f7ff6b0331c9341c26b471f7be41575d9c9ee6f5f5...</td>\n",
       "      <td>2015-03-17 11:11:11+00:00</td>\n",
       "      <td>1843891497</td>\n",
       "      <td>819515606</td>\n",
       "      <td>460961560</td>\n",
       "      <td>295014247</td>\n",
       "      <td>204885107</td>\n",
       "      <td>150527670</td>\n",
       "      <td>115245044</td>\n",
       "      <td>91053383</td>\n",
       "      <td>73752814</td>\n",
       "      <td>99.75</td>\n",
       "      <td>76.8</td>\n",
       "      <td>0.985691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>434785</td>\n",
       "      <td>7795f7ff6b0331c9341c26b471f7be41575d9c9ee6f5f5...</td>\n",
       "      <td>2015-03-17 11:13:11+00:00</td>\n",
       "      <td>1843850253</td>\n",
       "      <td>819515606</td>\n",
       "      <td>460961560</td>\n",
       "      <td>295014247</td>\n",
       "      <td>204885107</td>\n",
       "      <td>150527670</td>\n",
       "      <td>115245044</td>\n",
       "      <td>91053383</td>\n",
       "      <td>73752814</td>\n",
       "      <td>99.75</td>\n",
       "      <td>76.8</td>\n",
       "      <td>0.985691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>434805</td>\n",
       "      <td>7795f7ff6b0331c9341c26b471f7be41575d9c9ee6f5f5...</td>\n",
       "      <td>2015-03-17 11:19:06+00:00</td>\n",
       "      <td>1843850253</td>\n",
       "      <td>819515606</td>\n",
       "      <td>460961561</td>\n",
       "      <td>295014247</td>\n",
       "      <td>204885107</td>\n",
       "      <td>150527670</td>\n",
       "      <td>115245044</td>\n",
       "      <td>91053383</td>\n",
       "      <td>73752814</td>\n",
       "      <td>99.75</td>\n",
       "      <td>76.8</td>\n",
       "      <td>0.985691</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   measurement_id                                          device_id  \\\n",
       "0          434778  7795f7ff6b0331c9341c26b471f7be41575d9c9ee6f5f5...   \n",
       "1          434782  7795f7ff6b0331c9341c26b471f7be41575d9c9ee6f5f5...   \n",
       "2          434783  7795f7ff6b0331c9341c26b471f7be41575d9c9ee6f5f5...   \n",
       "3          434785  7795f7ff6b0331c9341c26b471f7be41575d9c9ee6f5f5...   \n",
       "4          434805  7795f7ff6b0331c9341c26b471f7be41575d9c9ee6f5f5...   \n",
       "\n",
       "                  timestamp     grid_id grid_id300 grid_id400 grid_id500  \\\n",
       "0 2015-03-17 11:06:42+00:00  1843891497  819515606  460961560  295014247   \n",
       "1 2015-03-17 11:10:43+00:00  1843891497  819515606  460961560  295014247   \n",
       "2 2015-03-17 11:11:11+00:00  1843891497  819515606  460961560  295014247   \n",
       "3 2015-03-17 11:13:11+00:00  1843850253  819515606  460961560  295014247   \n",
       "4 2015-03-17 11:19:06+00:00  1843850253  819515606  460961561  295014247   \n",
       "\n",
       "  grid_id600 grid_id700 grid_id800 grid_id900 grid_id1000  regularity  \\\n",
       "0  204885107  150527670  115245044   91053383    73752814       99.75   \n",
       "1  204885107  150527670  115245044   91053383    73752814       99.75   \n",
       "2  204885107  150527670  115245044   91053383    73752814       99.75   \n",
       "3  204885107  150527670  115245044   91053383    73752814       99.75   \n",
       "4  204885107  150527670  115245044   91053383    73752814       99.75   \n",
       "\n",
       "   stationarity  diversity  \n",
       "0          76.8   0.985691  \n",
       "1          76.8   0.985691  \n",
       "2          76.8   0.985691  \n",
       "3          76.8   0.985691  \n",
       "4          76.8   0.985691  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute metrics for other grid lengths (300 meters to 1 km)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing metrics for grid of side length = 300 meters\n",
      "Processing user 20/61\n",
      "Processing user 40/61\n",
      "Processing user 60/61\n",
      "Computing metrics for grid of side length = 400 meters\n",
      "Processing user 20/61\n",
      "Processing user 40/61\n",
      "Processing user 60/61\n",
      "Computing metrics for grid of side length = 500 meters\n",
      "Processing user 20/61\n",
      "Processing user 40/61\n",
      "Processing user 60/61\n",
      "Computing metrics for grid of side length = 600 meters\n",
      "Processing user 20/61\n",
      "Processing user 40/61\n",
      "Processing user 60/61\n",
      "Computing metrics for grid of side length = 700 meters\n",
      "Processing user 20/61\n",
      "Processing user 40/61\n",
      "Processing user 60/61\n",
      "Computing metrics for grid of side length = 800 meters\n",
      "Processing user 20/61\n",
      "Processing user 40/61\n",
      "Processing user 60/61\n",
      "Computing metrics for grid of side length = 900 meters\n",
      "Processing user 20/61\n",
      "Processing user 40/61\n",
      "Processing user 60/61\n",
      "Computing metrics for grid of side length = 1000 meters\n",
      "Processing user 20/61\n",
      "Processing user 40/61\n",
      "Processing user 60/61\n"
     ]
    }
   ],
   "source": [
    "if df_name == \"macaco\":\n",
    "    for i in range(300, 1100, 100):\n",
    "        print(\"Computing metrics for grid of side length = {} meters\".format(i))\n",
    "        s = str(i)\n",
    "        regularities, stationarities, diversities = compute_metrics(df, 'grid_id' + s)\n",
    "        df['regularity' + s] = df.apply(lambda row: regularities[row['device_id']], axis=1)\n",
    "        df['stationarity' + s] = df.apply(lambda row: stationarities[row['device_id']], axis=1)\n",
    "        df['diversity' + s] = df.apply(lambda row: diversities[row['device_id']], axis=1)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute Entropy and Predictability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_entropy_and_predictability(df, colname):\n",
    "    base_entropy = defaultdict()\n",
    "    actual_entropy = defaultdict()\n",
    "    baseline_predictability = defaultdict()\n",
    "    actual_predictability = defaultdict()\n",
    "    \n",
    "    nr_users = len(set(df['device_id']))\n",
    "    curr_user = 0\n",
    "    for device_id, grp in df.groupby(df['device_id']):\n",
    "        curr_user += 1        \n",
    "        if curr_user % 20 == 0:\n",
    "            print(\"Processing user {}/{}\".format(str(curr_user), str(nr_users)))\n",
    "        \n",
    "        # Filter and convert the list of locations to a list of strings, which \n",
    "        # is the necessary format for the functions that compute the entropy.\n",
    "        locations = list(grp[colname])\n",
    "        sequence = [str(location) for location in locations]\n",
    "\n",
    "        # Adjust the size of the sequence so that we don't interfere with\n",
    "        # the calculations of the metrics that depend on the size.\n",
    "        n = len(set(sequence))\n",
    "\n",
    "        base_entropy[device_id] = baseline_entropy(sequence)\n",
    "        actual_entropy[device_id] = entropy_kontoyiannis(sequence)\n",
    "        actual_predictability[device_id] = max_predictability(actual_entropy[device_id], n)\n",
    "        baseline_predictability[device_id] = max_predictability(base_entropy[device_id], n)\n",
    "\n",
    "    return base_entropy, actual_entropy, baseline_predictability, actual_predictability\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing user 20/61\n",
      "Processing user 40/61\n",
      "Processing user 60/61\n"
     ]
    }
   ],
   "source": [
    "base_entropy, actual_entropy, baseline_predictability, actual_predictability = compute_entropy_and_predictability(df, 'grid_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['baseline_entropy'] = df.apply(lambda row: base_entropy[row['device_id']], axis=1)\n",
    "df['actual_entropy'] = df.apply(lambda row: actual_entropy[row['device_id']], axis=1)\n",
    "df['baseline_predictability'] = df.apply(lambda row: baseline_predictability[row['device_id']], axis=1)\n",
    "df['actual_predictability'] = df.apply(lambda row: actual_predictability[row['device_id']], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if df_name == \"macaco\":\n",
    "    for i in range(300, 1100, 100):\n",
    "        print(\"Computing entropy for grid of side length = {} meters\".format(i))\n",
    "        s = str(i)\n",
    "        base_entropy, actual_entropy, baseline_predictability, actual_predictability = compute_entropy_and_predictability(df, 'grid_id' + s)\n",
    "        df['baseline_entropy' + s] = df.apply(lambda row: base_entropy[row['device_id']], axis=1)\n",
    "        df['actual_entropy' + s] = df.apply(lambda row: actual_entropy[row['device_id']], axis=1)\n",
    "        df['baseline_predictability' + s] = df.apply(lambda row: baseline_predictability[row['device_id']], axis=1)\n",
    "        df['actual_predictability' + s] = df.apply(lambda row: actual_predictability[row['device_id']], axis=1)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_entropy_and_predictability_with_context(df):\n",
    "    stats = defaultdict(list)\n",
    "    nr_users = len(set(df['device_id']))\n",
    "    curr_user = 0\n",
    "    for device_id, grp in df.groupby(df['device_id']):\n",
    "        curr_user += 1        \n",
    "        if curr_user % 20 == 0:\n",
    "            print(\"Processing user {}/{}\".format(str(curr_user), str(nr_users)))\n",
    "        \n",
    "        # Build the sequences for which we will compute entropy and predictability\n",
    "        sequence = [str(item) for item in grp['grid_id']]\n",
    "        weekday_contexts = [str(item.weekday()) for item in grp['timestamp']]\n",
    "        hourofday_contexts = [str(item.hour) for item in grp['timestamp']]\n",
    "        \n",
    "        # Sequence concatenating\n",
    "        entropy_seq_concat_weekday = sequence_concatenating(sequence, weekday_contexts)\n",
    "        entropy_seq_concat_hourofday = sequence_concatenating(sequence, hourofday_contexts)\n",
    "        predictability_seq_concat_weekday = max_predictability(entropy_seq_concat_weekday, len(set(sequence)))\n",
    "        predictability_seq_concat_hourofday = max_predictability(entropy_seq_concat_hourofday, len(set(sequence)))\n",
    "        \n",
    "        # Sequence merging\n",
    "        entropy_seq_merge_weekday = sequence_merging(sequence, weekday_contexts)\n",
    "        entropy_seq_merge_hourofday = sequence_merging(sequence, hourofday_contexts)\n",
    "        predictability_seq_merge_weekday = max_predictability(entropy_seq_merge_weekday, len(set(sequence)))\n",
    "        predictability_seq_merge_hourofday = max_predictability(entropy_seq_merge_hourofday, len(set(sequence)))\n",
    "        \n",
    "        # Add metrics to dictionary to be processed later\n",
    "        stats[device_id].append((entropy_seq_concat_weekday, entropy_seq_merge_weekday, predictability_seq_concat_weekday, predictability_seq_merge_weekday))\n",
    "        stats[device_id].append((entropy_seq_concat_hourofday, entropy_seq_merge_hourofday, predictability_seq_concat_hourofday, predictability_seq_merge_hourofday))\n",
    "        \n",
    "        # This code will execute only for CDR dataset, which has weather information\n",
    "        if 'weather_main' in df.columns:\n",
    "            weather_contexts = [str(item) for item in grp['weather_main']]\n",
    "            \n",
    "            # Sequence concatenating for weather info\n",
    "            entropy_seq_concat_weather = sequence_concatenating(sequence, weather_contexts)\n",
    "            predictability_seq_concat_weather = max_predictability(entropy_seq_concat_weather, len(set(sequence)))\n",
    "\n",
    "            # Sequence merging for weather info            \n",
    "            entropy_seq_merge_weather = sequence_merging(sequence, weather_contexts)\n",
    "            predictability_seq_merge_weather = max_predictability(entropy_seq_merge_weather, len(set(sequence)))\n",
    "            \n",
    "            stats[device_id].append((entropy_seq_concat_weather, entropy_seq_merge_weather, predictability_seq_concat_weather, predictability_seq_merge_weather))\n",
    "        # For the GPS dataset, we fill in weather values with zeroes, so that they will be ignored later\n",
    "        else:\n",
    "            stats[device_id].append((0, 0, 0, 0))\n",
    "\n",
    "    return stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing user 20/61\n",
      "Processing user 40/61\n",
      "Processing user 60/61\n"
     ]
    }
   ],
   "source": [
    "stats = compute_entropy_and_predictability_with_context(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "context_types = ['weekday', 'hourofday']\n",
    "if 'weather_main' in df.columns: # Will execute only for the CDR dataset\n",
    "    context_types.append('weather')\n",
    "\n",
    "# Compute context-related metrics (entropy and predictability) for the sequences of contexts\n",
    "for user_i, context in enumerate(context_types):\n",
    "    df['entropy_seq_concat_' + context] = df.apply(lambda row: stats[row['device_id']][user_i][0], axis=1)\n",
    "    df['entropy_seq_merge_' + context] = df.apply(lambda row: stats[row['device_id']][user_i][1], axis=1)\n",
    "    df['predictability_seq_concat_' + context] = df.apply(lambda row: stats[row['device_id']][user_i][2], axis=1)\n",
    "    df['predictability_seq_merge_' + context] = df.apply(lambda row: stats[row['device_id']][user_i][3], axis=1)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write the final dataset to be analyzed by a separate script.\n",
    "df.to_csv(os.path.join(data_dir, df_name + '_tsas_' + df_type + '.tsv'), sep='\\t', encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
